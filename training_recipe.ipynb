{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTcpk3_UGEnR"
      },
      "source": [
        "# Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9aqvdcQ5F0dF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihz6A1uuF49L",
        "outputId": "ec0f769c-c0ee-40f2-912f-379a50e95622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 110 entries, 0 to 109\n",
            "Data columns (total 3 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   incident_id  100 non-null    float64\n",
            " 1   description  110 non-null    object \n",
            " 2   priority     110 non-null    object \n",
            "dtypes: float64(1), object(2)\n",
            "memory usage: 2.7+ KB\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"security_incidents_dataset.csv\")\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeHgQzdfGOy4"
      },
      "source": [
        "### As the dataset is small, the models are likely to get overfitted. To reduce this, I am choosing a model with lower complexity.\n",
        "\n",
        "- I am took four classification models\n",
        "  - LogisticRegression\n",
        "  - SVC\n",
        "  - RandomForestClassifier\n",
        "  - GaussianNB\n",
        "\n",
        "\n",
        "- selecting a model with best score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jCD0N15AH8w5"
      },
      "outputs": [],
      "source": [
        "# Import models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Import modules for model evaluation and embeddings\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCKreNABCtJ1",
        "outputId": "82769f3c-3539-46c4-8129-b6a92faad91c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression CV F1 scores: [1.         1.         1.         1.         0.94035088], Average: 0.9881\n",
            "SVM CV F1 scores: [1.         1.         1.         1.         0.94035088], Average: 0.9881\n",
            "Random Forest CV F1 scores: [1.         0.8875     1.         0.94035088 0.75714286], Average: 0.9170\n",
            "Gaussian NB CV F1 scores: [1. 1. 1. 1. 1.], Average: 1.0000\n",
            "\n",
            "Best model: Gaussian NB with CV F1: 1.0000\n",
            "\n",
            "Test Set Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       1.00      1.00      1.00        11\n",
            "         Low       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        22\n",
            "   macro avg       1.00      1.00      1.00        22\n",
            "weighted avg       1.00      1.00      1.00        22\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Encode the description\n",
        "X = df[\"description\"].tolist()\n",
        "y = df[\"priority\"]\n",
        "\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "X_emb = embedder.encode(X)\n",
        "\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X_emb, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "\n",
        "# Defining the models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"SVM\": SVC(probability=True),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
        "    \"Gaussian NB\": GaussianNB()\n",
        "}\n",
        "\n",
        "\n",
        "best_score = 0\n",
        "best_model_name = None\n",
        "best_model = None\n",
        "\n",
        "for name, model in models.items():\n",
        "    scores = cross_val_score(\n",
        "        model, X_train, y_train,\n",
        "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "        scoring=\"f1_macro\"\n",
        "    )\n",
        "    print(f\"{name} CV F1 scores: {scores}, Average: {scores.mean():.4f}\")\n",
        "\n",
        "    if scores.mean() > best_score:\n",
        "        best_score = scores.mean()\n",
        "        best_model_name = name\n",
        "        best_model = model\n",
        "\n",
        "print(f\"\\nBest model: {best_model_name} with CV F1: {best_score:.4f}\")\n",
        "\n",
        "# Train the best model with full training set\n",
        "best_model.fit(X_train, y_train)\n",
        "y_pred_test = best_model.predict(X_test)\n",
        "\n",
        "print(\"\\nTest Set Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a8be9mrKlJs"
      },
      "source": [
        "### It is clear that the models are overfitting the data, as the dataset was generated using ChatGPT. To overcome this problem, we should increase the dataset size. For now, this is the best approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMvePr28FBrG",
        "outputId": "f42ab66d-2222-4263-dbf7-c7306d694b32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions for new incidents: ['High' 'Low']\n"
          ]
        }
      ],
      "source": [
        "# testing with new samples\n",
        "new_samples = [\n",
        "    \"Unknown person loitering near the front gate\", # it is high\n",
        "    \"Delivery person left package at the doorstep\" # It is Low\n",
        "]\n",
        "new_emb = embedder.encode(new_samples)\n",
        "preds = best_model.predict(new_emb)\n",
        "print(\"Predictions for new incidents:\", preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiV4t6reLobt"
      },
      "source": [
        "## Lets create a pipeline - to streamline preprocessing, feature extraction, and model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "i5bay1eaJdTr"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xL3My_7GMhBH"
      },
      "outputs": [],
      "source": [
        "def embed_text(texts):\n",
        "    return embedder.encode(texts)\n",
        "\n",
        "embedding_transformer = FunctionTransformer(embed_text, validate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NrpgBQs6Mlj7"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    (\"embeddings\", embedding_transformer),\n",
        "    (\"classifier\", best_model)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ansuNhBDMnaG",
        "outputId": "19c3aad3-7eca-4558-ea8e-279aa6ad3e65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['High', 'Low'], dtype='<U4')"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline.predict(new_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnJrjcr8MzM2"
      },
      "source": [
        "## Lets save the pipeline\n",
        "\n",
        "###lets call our model the \"Security Description Classifier\" - SDC.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBz_dN5lMvRU",
        "outputId": "6ced10db-0287-41e8-eb1a-824eb4b3c986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline saved as 'SDC_pipeline.pkl'\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(pipeline, \"SDC_pipeline.pkl\")\n",
        "print(\"Pipeline saved as 'SDC_pipeline.pkl'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFojZhs_M7ZI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "zeexai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
